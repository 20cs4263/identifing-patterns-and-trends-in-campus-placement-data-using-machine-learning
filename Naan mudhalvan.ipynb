 #Importing the libraries

import numpy as np
import pandas as pd
import os 

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import svm 
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics 
from sklearn.model_selection import cross_val_score
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
from sklearn.metrics import accuracy_score

#Read the Dataset

df=pd.read_csv(r"/content/collegeplace.csv")
df.head()

#Handling Missing Values

df.info()

df.isnull().sum()

# handling outliers
def transformationplot(feature):
    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    sns.displot(feature)

Transformationplot(np.log(df['Age']))

#Handling Categorical Values

df=df.replace(['Male'],[0])
df=df.replace(['Female'],[1])
df=df.replace(['Computer Science','Information Technology','Electronics And Communication','Mechanical','Electrical','Civil'],[0,1,2,3,4,5])

df=df.drop(['Hostel'],axis=1)

df
# Univariate Analysis

plt.figure(figsize=(12,5))
plt.subplot(121)
sns.distplot(df['CGPA'],color='r')

plt.figure(figsize=(12,5))
plt.subplot(121)
sns.displot(df['PlaceOrNot'],color='r')

#Bivariate Analysis
#plotting the count plot
plt.figure(figsize=(18,4))
plt.subplot(1,4,1)
sns.countplot(data['Gender'])
plt.subplot(1,4,1)
sns.countplot(data['Education'])
plt.show()


#Multivariate Analysis

plt.figure(figsize=(20,5))
plt.subplot(131)
sns.countplot(df['PlaceOrNot'],hue=df['CGPA'])

sns.swarmplot(df['PlaceOrNot'],df['CGPA'],hue=df['Stream'])

#Scaling The Data

sc=StandardScalar()
x_bal=sc.fit_transform(x_bal)

x_bal=pd.Dataform(x_bal,columns=names)

#Splitting The Data Into Train And Test
x=Standardized_data
y=df['PlacedOrNot']

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2, stratify=Y, random_state=2)


#SVM Model
classifier=svm.SVC(kernel='linear')

classifier.fit(x_train, y_train)

x_train_prediction=classifier.predict(x_train)
training_data_accuracy=accuracy_score(x_train_prediction,y_train)

print('Accuracy Score of the training data:', training_data_accuracy)

#KNN Model
best_k={'Register':0}
best_score={'Regular':0}
for K in range(3,50,2):
    ##using Regular training set
    knn_temp=KNeighborsclassifier(n_neighbors=K)
    knn_temp.fit(x_train,y_train)
    knn_temp_pred=knn_temp.predict(x_test)
    score=metrics.accuracy_score(y_test,knn_temp_pred)
    if score >= best_score['Regular'] and score<100:
        best_score['Regular']=score
        best_k['Regular']=k

print("---Results---\nk: {}\nScore: {}".format(best_k,best_score))
## Instantiate the models
knn=KNeighborsClassifier(n_neighbors=best_k["Regular"])
##fit the model to the training set
knn.fit(x_train,y_train)
knn_pred=knn.predict(x_test)
testd=accuracy_score(knn_pred,y_test)

#neural network model
import tensorflow as tf
from tensorflow import keres
from keras.models import sequential
from tensorflow.keras import layers

classifier = sequential()

#add input layer and first hidden layer
classifier.add(keras.layers.Dense(6,activation='relu',input_din=6))
classifier.add(keras.layers.Dropout(0,50))
#add 2nd hidden layer
classifier.add(keras.layers.Dense(6,activation='relu'))
classifier.add(keras.layers.Dropout(0,50))

#final or output layer
classifier.add(keras.layers.Dense(1,activation='signoid'))

[] #compling the model

lnss_1=tf.keras.losses.BinaryCrossentropy()

classifier.compile(optimizer='Adan',loss=loss_1,metrics=['accuracy'])

[] #fitting the model
classifier.fit(x_train,y_train,batch_size=20,epochs=100)


#save the best model
import pickle

pickle.dump(knn,open("placement.pk1",'wb'))
model=pickle.load(open('placement.pk1','rb'))

#

sectionId = "hero",class="d-flex flex-column justify-content-center">
<div class="container">
 <div class="row justify-content-center">
  <div class="col-xl-8">
   <h1>Identifying patterns and Trends in Campus Placement Data using Machine Learning</h1>
  </div>
 </div>
</div>
</section><!-- End Hero-->
   

#Buliding Html Pages(Pat-2)

<section id="about" class="about">
  <div class="container">

   <div class="section-title">
     <h2>Fill the details</h2>

   <div class="row content">
     <div class="first">
      <from action="{{ url_for('y_predict')}}"methode="POST">
          <input type="number" id="sem1" name="sem1" placeholder="Age">
          <input type="number" id="sem2" name="sem2" placeholder="GendeM(0),F(0)">
          <input type="number" id="sen3" name="sem3" placeholder="Stream CS(0),IT(1),ECE(2),Mech(3),EEE(4)">
          <input type="number" id="sem4" name="sem4" placeholder="Internships">
          <input type="number" id="sem5" name="sem5" placeholder="CGPA">
          <input type="number" id="sem6" name="sem6" placeholder="Number of backlags">
          <input type="submit" value="Submit">
        </form>
    </div>
  </div>

#  Import the Libraries

from flask import Flask,render_template,request
app=Flask(__name__)
import pickle
import joblib
model=pickle.load(open("placement123.pkl",'rb'))
ct=joblib.load('placement')
               
#Render HTML Page

@app.route('/')
def hello():
    return render_template("index.html")


#Main Function

 app.run(debug=True)
            

